- name: Add additional master nodes
  hosts: k8s_masters[1:] # skip the first master
  become: yes
  vars_files:
    - ../vars.yaml

  vars:
    kubeconfig: /etc/kubernetes/admin.conf
    kube_home: /home/ubuntu
    kube_dir: "{{ kube_home }}/.kube"

  tasks:

    - name: Upload certificates on first master and get certificate key
      delegate_to: "{{ groups['k8s_masters'][0] }}"
      shell: kubeadm init phase upload-certs --upload-certs | sed -n '3p'
      register: cert_key
      changed_when: false
      run_once: true

    - name: Generate join command for additional master nodes
      delegate_to: "{{ groups['k8s_masters'][0] }}"
      shell: kubeadm token create --print-join-command --certificate-key {{ cert_key.stdout }}
      register: join_command
      changed_when: false
      run_once: true

    - name: Get current nodes in cluster
      delegate_to: "{{ groups['k8s_masters'][0] }}"
      shell: kubectl get nodes -o name
      register: node_check
      changed_when: false
      environment:
        KUBECONFIG: "{{ kubeconfig }}"
      run_once: true

    - name: Check if this node is already part of the cluster
      set_fact:
        node_already_joined: "{{ 'node/' + inventory_hostname in node_check.stdout_lines }}"

    - name: Skip adding the node if it is already part of the cluster
      debug:
        msg: "Node {{ inventory_hostname }} is already part of the cluster."
      when: node_already_joined

    - name: Add the node as master node
      command: "{{ join_command.stdout }}"
      when: not node_already_joined

    - name: Ensure .kube directory exists
      file:
        path: "{{ kube_dir }}"
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0700'

    - name: Copy kubeconfig to user home
      copy:
        src: "{{ kubeconfig }}"
        dest: "{{ kube_dir }}/config"
        owner: ubuntu
        group: ubuntu
        mode: '0600'
        remote_src: yes
        
    - name: Remove control-plane taint from current master to allow scheduling
      shell: >
        if kubectl get node {{ inventory_hostname }} -o jsonpath='{.spec.taints[?(@.key=="node-role.kubernetes.io/control-plane")].effect}' | grep -q "NoSchedule"; then
          kubectl taint node {{ inventory_hostname }} node-role.kubernetes.io/control-plane:NoSchedule-
        fi
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      when: allow_scheduling_on_master_nodes | bool
      register: taint_result
      changed_when: "'taint' in taint_result.stdout or 'taint' in taint_result.stderr"

    - name: Rollout restart CoreDNS to ensure it runs on different master nodes
      shell: kubectl -n kube-system rollout restart deployment coredns
      environment:
        KUBECONFIG: "{{ kubeconfig }}"
      run_once: true

    - name: Set KUBECONFIG environment variable
      lineinfile:
        path: /home/ubuntu/.bashrc
        line: 'export KUBECONFIG=~/.kube/config'
        state: present
        create: yes
        owner: ubuntu
        group: ubuntu
        mode: '0644'

    - name: Set KUBE_EDITOR environment variable
      lineinfile:
        path: /home/ubuntu/.bashrc
        line: "export KUBE_EDITOR={{ kube_editor }}"
        state: present
        owner: ubuntu
        group: ubuntu
        mode: '0644'
